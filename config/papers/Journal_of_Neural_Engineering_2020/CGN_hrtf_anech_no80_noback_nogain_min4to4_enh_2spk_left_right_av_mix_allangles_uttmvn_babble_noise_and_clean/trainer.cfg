[trainer]
#The type of trainer: single task or multi task
trainer = multi_task
#state the tasks
tasks = task_2spk
#a space separated list of different semgent lengths that will be used. Expecting 'full' to be the last one.
#Normally a network for a specific segment length is initliazed with the network of the previous segment length
#should be specified in tasks?
segment_lengths = 100 full
#number of passes over the entire database
num_epochs = 100
#initial learning rate of the neural net
initial_learning_rate = 1e-3 5e-4
#exponential weight decay parameter. 
#For segment length 100: no decay. For full: after 1 epoch there is a decay of 0.875 (which was best in a previous experiment)
learning_rate_decay = 1 1.5878e-6
#cliping value for gradients
clip_grad_value = 20000000
#normalize gradients?
normalize_gradients = True
#a space separated list of size of the minibatch (#utterances), depending on the segment length
batch_size = 400 32
#a  pace separated list of number of minibatches to aggregate before updating the parameters, 
#depending on the segment length. if 0 asstnchronous training will be done
numbatches_to_aggregate = 2 4
#the data will be divided into buckets according to sequence length, this
#setting determines the number of buckets to use. For no bucketing set to 1
numbuckets = 1

###VALIDATION PART###
#frequency of evaluating the validation set.
valid_frequency = 150
#if you want to adapt the learning rate based on the validation set, set to True
valid_adapt = False
#if you want to go back in training if validation performance is worse set to True
go_back = False
#the number of times validation performance can be worse before terminating training, set to None to disable early stopping
num_tries = 3
#set to True if you want to reset the number of tries if the validation performance is better
reset_tries = True

[task_2spk]
#type of loss that should be used
loss_type = pit_sigmoid
linkedsets = noisy clean
linkedset_weighting = 1.0 1.0
#a space separated list of the inputs of the (hybrid) model
inputs = left_features right_features recs1 recs2 spatial_features
#the outputs requested for this task
outputs = bin_est
#a space separated list of the nodes of the (hybrid) model (includes
#the output nodes)
nodes = conc0 conc1 conc2 conc3 main1 main2 bin_est1 bin_est2 bin_est
#for each node, state a model and a space separated list of inputs
#
conc0_model = concat
conc0_inputs = left_features right_features
#
conc1_model = concat
conc1_inputs = conc0 spatial_features
#
conc2_model = concat
conc2_inputs = conc1 recs1
#
main1_model = main
main1_inputs = conc2
#
bin_est1_model = outlayer
bin_est1_inputs = main1
#
conc3_model = concat
conc3_inputs = conc1 recs2
#
main2_model = main
main2_inputs = conc3
#
bin_est2_model = outlayer
bin_est2_inputs = main2
#
bin_est_model = concat
bin_est_inputs = bin_est1 bin_est2

#a mapping between the input names and database sections
noisy_left_features = trainleftspec
noisy_right_features = trainrightspec
noisy_spatial_features = trainangles
noisy_recs1 = trainrecs1spec
noisy_recs2 = trainrecs2spec
clean_left_features = traincleanleftspec
clean_right_features = traincleanrightspec
clean_spatial_features = traincleanangles
clean_recs1 = traincleanrecs1spec
clean_recs2 = traincleanrecs2spec
#a space seperated list of target names used by the trainer
targets = multi_targets mix_to_mask
#a mapping between the target names and database sections
noisy_multi_targets = traintargets
clean_multi_targets = traincleantargets
#a mapping between the target names and database sections
noisy_mix_to_mask = trainmixtomask
clean_mix_to_mask = traincleanmixtomask