[hyper]
model_names = main outlayer speaker_embeddings_model attractor_layer id_net id_outlayer

[main]
#type of architecture
architecture = dbresetlstm
#whether or not to separate the forward and backward direction
separate_directions = False
#number of neurons in the hidden layers
num_units = 600
#the reset cycle period
t_reset = 10
#the group size
group_size = 1
#reset in both directions? Default is True
forward_reset = True
backward_reset = True
#number of hidden layers
num_layers = 2
#input noise standart deviation
input_noise = 0.2
#dropout rate (keep probability)
dropout = 1.0
#the recurrent dropout rate (keep probability)
recurrent_dropout = 1.0
#wheter layer normalization should be applied
layer_norm = False

[outlayer]
#type of architecture
architecture = linear
#the number of output dims (should be set automaticaly?)
output_dims = 2580
no_bias = True
#input noise standart deviation
input_noise = 0
#dropout rate (keep probability)
dropout = 1.0

[speaker_embeddings_model]
#type of architecture
architecture = linear
#the number of output dims (should be set automaticaly?)
output_dims = 2580
no_bias = True
#input noise standart deviation
input_noise = 0
#dropout rate (keep probability)
dropout = 1.0

[attractor_layer]
#type of architecture
architecture = attractor

[id_net]
#type of architecture
architecture = feedforward
num_layers = 2
num_units = 100
#input noise standart deviation
input_noise = 0
#dropout rate (keep probability)
dropout = 1.0

[id_outlayer]
#type of architecture
architecture = linear
#the number of output dims (should be set automaticaly?)
output_dims = 101
no_bias = True
#input noise standart deviation
input_noise = 0
#dropout rate (keep probability)
dropout = 1.0
