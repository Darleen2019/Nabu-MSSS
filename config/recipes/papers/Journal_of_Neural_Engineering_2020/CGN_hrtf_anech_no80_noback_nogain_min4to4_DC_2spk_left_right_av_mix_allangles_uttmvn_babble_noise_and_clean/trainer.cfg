[trainer]
#The type of trainer: single task or multi task
trainer = multi_task
#state the tasks
tasks = task_2spk
#a space separated list of different semgent lengths that will be used. Expecting 'full' to be the last one.
#Normally a network for a specific segment length is initliazed with the network of the previous segment length
#should be specified in tasks?
segment_lengths = 100 full
#number of passes over the entire database
num_epochs = 100
#initial learning rate of the neural net
initial_learning_rate = 1e-3 5e-4
#exponential weight decay parameter. 
#For segment length 100: no decay. For full: after 1 epoch there is a decay of 0.875 (which was best in a previous experiment)
learning_rate_decay = 1 1.5878e-6
#cliping value for gradients
clip_grad_value = 20000000
#normalize gradients?
normalize_gradients = True
#a space separated list of size of the minibatch (#utterances), depending on the segment length
batch_size = 200 32
#a  pace separated list of number of minibatches to aggregate before updating the parameters, 
#depending on the segment length. if 0 asstnchronous training will be done
numbatches_to_aggregate = 4 4
#the data will be divided into buckets according to sequence length, this
#setting determines the number of buckets to use. For no bucketing set to 1
numbuckets = 1

###VALIDATION PART###
#frequency of evaluating the validation set.
valid_frequency = 150
#if you want to adapt the learning rate based on the validation set, set to True
valid_adapt = False
#if you want to go back in training if validation performance is worse set to True
go_back = False
#the number of times validation performance can be worse before terminating training, set to None to disable early stopping
num_tries = 3
#set to True if you want to reset the number of tries if the validation performance is better
reset_tries = True

[task_2spk]
#type of loss that should be used
loss_type = deepclusteringnoise
linkedsets = noisy clean
linkedset_weighting = 1.0 1.0
#a space separated list of the inputs of the (hybrid) model
inputs = left_features right_features spatial_features
#the outputs requested for this task
outputs = bin_emb noise_filter
#a space separated list of the nodes of the (hybrid) model (includes
#the output nodes)
nodes = n0 n1 n2 bin_emb noise_filter
#for each node, state a model and a space separated list of inputs
#
n0_model = concat
n0_inputs = left_features right_features
#
n1_model = concat
n1_inputs = n0 spatial_features
#
n2_model = main
n2_inputs = n1
#
bin_emb_model = outlayer
bin_emb_inputs = n2
#
noise_filter_model = noisefilterlayer
noise_filter_inputs = n2

#a mapping between the input names and database sections
noisy_left_features = trainleftspec
noisy_right_features = trainrightspec
noisy_spatial_features = trainangles
clean_left_features = traincleanleftspec
clean_right_features = traincleanrightspec
clean_spatial_features = traincleanangles
#a space seperated list of target names used by the trainer
targets = binary_targets rel_speech_targets usedbins noisybins
#a mapping between the target names and database sections
noisy_binary_targets = traintargets
clean_binary_targets = traincleantargets
#a mapping between the target names and database sections
noisy_rel_speech_targets = trainrelspeechtargets
clean_rel_speech_targets = traincleanrelspeechtargets
#a mapping between the target names and database sections
noisy_usedbins = trainusedbins
clean_usedbins = traincleanusedbins
#a mapping between the target names and database sections
noisy_noisybins = trainnoisybins
clean_noisybins = traincleannoisybins